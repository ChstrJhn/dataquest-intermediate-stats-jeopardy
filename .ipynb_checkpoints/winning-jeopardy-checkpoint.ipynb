{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning our Data\n",
    "First we have to clean up the formatting of our column names and normalise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n",
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "print(jeopardy.columns)\n",
    "jeopardy.columns = jeopardy.columns.str.strip()\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    For the last 8 years of his life, Galileo was ...\n",
      "1    No. 2: 1912 Olympian; football star at Carlisl...\n",
      "2    The city of Yuma in this state has a record av...\n",
      "3    In 1963, live on \"The Art Linkletter Show\", th...\n",
      "4    Signer of the Dec. of Indep., framer of the Co...\n",
      "Name: Question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy[\"Question\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the last 8 years of his life galileo was under house arrest for espousing this mans theory\n",
      "copernicus\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "def qa_normaliser(row):\n",
    "    row = row.lower()\n",
    "    row = ''.join(i for i in row if i not in punct)\n",
    "    return row\n",
    "\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"Question\"].apply(qa_normaliser)\n",
    "print(jeopardy[\"clean_question\"].iloc[0])\n",
    "\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"Answer\"].apply(qa_normaliser)\n",
    "print(jeopardy[\"clean_answer\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         200\n",
      "1         200\n",
      "2         200\n",
      "3         200\n",
      "4         200\n",
      "5         200\n",
      "6         400\n",
      "7         400\n",
      "8         400\n",
      "9         400\n",
      "10        400\n",
      "11        400\n",
      "12        600\n",
      "13        600\n",
      "14        600\n",
      "15        600\n",
      "16        600\n",
      "17        600\n",
      "18        800\n",
      "19        800\n",
      "20        800\n",
      "21        800\n",
      "22       2000\n",
      "23        800\n",
      "24       1000\n",
      "25       1000\n",
      "26       1000\n",
      "27       1000\n",
      "28       1000\n",
      "29        400\n",
      "         ... \n",
      "19969    1200\n",
      "19970    1200\n",
      "19971    1500\n",
      "19972    1200\n",
      "19973    1200\n",
      "19974    1200\n",
      "19975    1600\n",
      "19976    1600\n",
      "19977    1600\n",
      "19978    1600\n",
      "19979    1600\n",
      "19980    1600\n",
      "19981    1200\n",
      "19982    2000\n",
      "19983    2000\n",
      "19984    2000\n",
      "19985    2000\n",
      "19986    2000\n",
      "19987       0\n",
      "19988     100\n",
      "19989     100\n",
      "19990     100\n",
      "19991     100\n",
      "19992     100\n",
      "19993     100\n",
      "19994     200\n",
      "19995     200\n",
      "19996     200\n",
      "19997     200\n",
      "19998     200\n",
      "Name: clean_value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def val_normaliser(row):\n",
    "    if row == \"None\":\n",
    "        row = 0\n",
    "    else:\n",
    "        row = ''.join(i for i in row if i not in punct)\n",
    "    return int(row)\n",
    "    \n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(val_normaliser)\n",
    "print(jeopardy[\"clean_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2004-12-31\n",
      "1        2004-12-31\n",
      "2        2004-12-31\n",
      "3        2004-12-31\n",
      "4        2004-12-31\n",
      "5        2004-12-31\n",
      "6        2004-12-31\n",
      "7        2004-12-31\n",
      "8        2004-12-31\n",
      "9        2004-12-31\n",
      "10       2004-12-31\n",
      "11       2004-12-31\n",
      "12       2004-12-31\n",
      "13       2004-12-31\n",
      "14       2004-12-31\n",
      "15       2004-12-31\n",
      "16       2004-12-31\n",
      "17       2004-12-31\n",
      "18       2004-12-31\n",
      "19       2004-12-31\n",
      "20       2004-12-31\n",
      "21       2004-12-31\n",
      "22       2004-12-31\n",
      "23       2004-12-31\n",
      "24       2004-12-31\n",
      "25       2004-12-31\n",
      "26       2004-12-31\n",
      "27       2004-12-31\n",
      "28       2004-12-31\n",
      "29       2004-12-31\n",
      "            ...    \n",
      "19969    2009-05-14\n",
      "19970    2009-05-14\n",
      "19971    2009-05-14\n",
      "19972    2009-05-14\n",
      "19973    2009-05-14\n",
      "19974    2009-05-14\n",
      "19975    2009-05-14\n",
      "19976    2009-05-14\n",
      "19977    2009-05-14\n",
      "19978    2009-05-14\n",
      "19979    2009-05-14\n",
      "19980    2009-05-14\n",
      "19981    2009-05-14\n",
      "19982    2009-05-14\n",
      "19983    2009-05-14\n",
      "19984    2009-05-14\n",
      "19985    2009-05-14\n",
      "19986    2009-05-14\n",
      "19987    2009-05-14\n",
      "19988    2000-03-14\n",
      "19989    2000-03-14\n",
      "19990    2000-03-14\n",
      "19991    2000-03-14\n",
      "19992    2000-03-14\n",
      "19993    2000-03-14\n",
      "19994    2000-03-14\n",
      "19995    2000-03-14\n",
      "19996    2000-03-14\n",
      "19997    2000-03-14\n",
      "19998    2000-03-14\n",
      "Name: Air Date, dtype: object\n",
      "0       2004-12-31\n",
      "1       2004-12-31\n",
      "2       2004-12-31\n",
      "3       2004-12-31\n",
      "4       2004-12-31\n",
      "5       2004-12-31\n",
      "6       2004-12-31\n",
      "7       2004-12-31\n",
      "8       2004-12-31\n",
      "9       2004-12-31\n",
      "10      2004-12-31\n",
      "11      2004-12-31\n",
      "12      2004-12-31\n",
      "13      2004-12-31\n",
      "14      2004-12-31\n",
      "15      2004-12-31\n",
      "16      2004-12-31\n",
      "17      2004-12-31\n",
      "18      2004-12-31\n",
      "19      2004-12-31\n",
      "20      2004-12-31\n",
      "21      2004-12-31\n",
      "22      2004-12-31\n",
      "23      2004-12-31\n",
      "24      2004-12-31\n",
      "25      2004-12-31\n",
      "26      2004-12-31\n",
      "27      2004-12-31\n",
      "28      2004-12-31\n",
      "29      2004-12-31\n",
      "           ...    \n",
      "19969   2009-05-14\n",
      "19970   2009-05-14\n",
      "19971   2009-05-14\n",
      "19972   2009-05-14\n",
      "19973   2009-05-14\n",
      "19974   2009-05-14\n",
      "19975   2009-05-14\n",
      "19976   2009-05-14\n",
      "19977   2009-05-14\n",
      "19978   2009-05-14\n",
      "19979   2009-05-14\n",
      "19980   2009-05-14\n",
      "19981   2009-05-14\n",
      "19982   2009-05-14\n",
      "19983   2009-05-14\n",
      "19984   2009-05-14\n",
      "19985   2009-05-14\n",
      "19986   2009-05-14\n",
      "19987   2009-05-14\n",
      "19988   2000-03-14\n",
      "19989   2000-03-14\n",
      "19990   2000-03-14\n",
      "19991   2000-03-14\n",
      "19992   2000-03-14\n",
      "19993   2000-03-14\n",
      "19994   2000-03-14\n",
      "19995   2000-03-14\n",
      "19996   2000-03-14\n",
      "19997   2000-03-14\n",
      "19998   2000-03-14\n",
      "Name: Air Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy[\"Air Date\"])\n",
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])\n",
    "print(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we study past questions, general knowledge, or not study at all?\n",
    "- How often the answer is deducible from the question.\n",
    "- How often new questions are repeats of older questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can answer the first question by seeing how many times words in the answer also occur in the question. We'll do this below, will a little bit of cleaning beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0582264069913\n",
      "0.006150307515375769\n",
      "0.8757437871893594\n"
     ]
    }
   ],
   "source": [
    "def find_match(row):\n",
    "    split_answer = row[\"clean_answer\"].split(\" \")\n",
    "    split_question = row[\"clean_question\"].split(\" \") \n",
    "    \n",
    "    split_answer = [i for i in split_answer if i not in (\"the\")]\n",
    "    \n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "        \n",
    "    match_count = 0   \n",
    "    \n",
    "    for i in split_answer:\n",
    "        if i in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "        \n",
    "    \n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(find_match,axis=1)\n",
    "\n",
    "\n",
    "print(jeopardy[\"answer_in_question\"].mean())\n",
    "print(len(jeopardy[jeopardy[\"answer_in_question\"] == 1.0])/len(jeopardy))\n",
    "print(len(jeopardy[jeopardy[\"answer_in_question\"] == 0])/len(jeopardy))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each returned value from the function is basically saying - \"Out of all the words in the question, this is the percentage of those words that match the words given in the answer (and vice versa).\" For example, if there's a match count of 9, and the length of the question is 10. there is a 90% match.\n",
    "\n",
    "\n",
    "By calculating the mean of all these match percentages, only 5.8% of the whole question contains words that fit the answer on average. In other words, it seems we can only gleam the answer from the question only ~ 5.8% of the time. Worse still, on average, only 0.6% of answers contain all the words mentioned in the question. 87% of the answers do not contain a single word from the question.\n",
    "\n",
    "Therefore, we can conclude that deducing the answer from the question is generally going to be fruitless. Since following this strategy is akin to shooting in the dark, two questions remain:\n",
    "\n",
    "- Should we study past questions? or ;\n",
    "- Should we cover all the bases and study general knowledge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706609081113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "for i,row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [i for i in split_question if len(i) > 5]    \n",
    "    match_count = 0\n",
    "    \n",
    "    for i in split_question:\n",
    "        if i in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(i)\n",
    "        \n",
    "    if len(split_question) > 0:\n",
    "        percentage = match_count / len(split_question)\n",
    "        \n",
    "    question_overlap.append(percentage)\n",
    "\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "print(jeopardy[\"question_overlap\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the match count keeps track of the frequency of the term used. For example, let's use the split_question = ['tiniest','indian','desert']. If both 'tiniest' and 'indian' have been used in prior questions, that means that there is a 2/3 overlap, or ~ 67% when the dataframe is sorted by date in descending order. \n",
    "\n",
    "Here, we find that the mean is ~ 70%. While the context of how the words are used within the question is taken out, it is a rough indication of that many of the terms are used time and again. If anything, it is a signal to investigate further if prior questions are recycled/rephrased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do terms really affect the value of the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baddie', 'hoochie', 'divides', 'hrefhttpwwwjarchivecommedia20060426j07mp3thisa', 'xenophon']\n",
      "High-low count:\n",
      "[(0, 1), (0, 1), (2, 2), (1, 0), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "def find_value(row):\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(find_value,axis=1)\n",
    "\n",
    "def high_low_count(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    for i,row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "\n",
    "for term in comparison_terms:\n",
    "    result = high_low_count(term)\n",
    "    observed_expected.append(result)\n",
    "\n",
    "print(comparison_terms)\n",
    "print(\"High-low count:\")\n",
    "print(observed_expected)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have our observed counts. For example, the term \"Valley\" is in 5 high value questions, and 29 low value questions. Now we can computer our expected counts and the chi-square value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40196284612688399, 0.52607729857054686], [0.40196284612688399, 0.52607729857054686], [0.88975496332255899, 0.34554371914834681], [2.4877921171956752, 0.11473257634454047], [0.40196284612688399, 0.52607729857054686]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for i in observed_expected:\n",
    "    total = sum(i)\n",
    "    total_prop = total/len(jeopardy)\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "\n",
    "    observed = np.array([i[0], i[1]])\n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    chisq,pval = chisquare(observed, expected)\n",
    "    chi_squared.append([chisq,pval])\n",
    "\n",
    "print(chi_squared) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All the p-values are above 0.05, which points to the use of terms not significantly different across both high and low value questions. However, a rule of thumb for chi-square tests is to have at least 3 observations, but alot of the terms have frequencies of less than that making our results pretty useless if i'm being honest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
